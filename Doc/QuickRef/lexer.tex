\chapter{Lexical parser generator}
\label{lexer}

The \golex tool is part of the standard \go system, but it is not a normal package. It is a tool that takes in the specification of a lexical parser (strictly a parser based on regular expressions) and generates a \go program that can parse \q{strings} into a list of tokens.

\begin{aside}
The \golex tool, and the \golex language, is closely modeled on the \q{lex} languae tool. Of course, it is slightly modified to be convenient for \go rather than C, and its implementation is not based on \q{lex}'s implementation.
\end{aside}

\subsection{The parts of a \golex file}

A typical \golex program looks like:
\begin{alltt}
-- The preamble ...
import go.stdparse.
yyTokType ::= FLT(float) | ID(string) | EOF.
\%\%
-- The rules ...
 [ \bsl{}n\bsl{}t\bsl{}b\bsl{}r]+ => skip     	-- ignore white space
 "--"[^\bsl{}n]*"\bsl{}n"		       	-- line comment
 "-"?[0-9]+("."[0-9]+([eE][-+]?[0-9]+)?) => (FLT(floatOf\%\%yyTok))
 [a-zA-Z_][a-zA-Z_0-9]* => (ID(yyTok))
-- Block comment uses a state
 "/*" => <comment>        	-- long comment
  <comment> "*/" => <initial>
  <comment> .	         	-- implies a skip
\%\%
-- The postamble
  private parseAll:[yyLexer]*.
  parseAll(Lx) ->
    Tok = Lx.nextToken();
    stdout.outLine("Token is "<>Tok.show());
    ( Tok.token()!=EOF?
        parseAll(Lx)).
  main([])::stdin.eof() -> {}.
  main([]) ->
      parseAll(yyTest(stdin.inLine("\bsl{}n"),0,0));
    main([]).
\end{alltt}


There are three parts to the \golex program: the preamble, the rules section and the postamble.
\begin{description}
\item[preamble]
The preamble section of a \golex file has to satisfy two key obectives: define the type of tokens found by the lexer and to ensure that any required \q{import} declarations are made.

If there are any \q{import} statements, they should be at the beginning of the section.

The \q{yyTokType} type declaration is mandatory and declares the types of tokens generated by the lexer. 

\begin{aside}
There is an additional requirement that may be removed in a future version: the constructor \q{EOF} must be declared for the \q{yyTokTpe}.
\end{aside}

\item[rules]
The rules section is typically the largest section and contains all the rules that make up the lexer.

\item[postamble]
The postamble section contains any definitions -- with their declarations -- that are referenced by the rules.
\end{description}

\section{\golex rules}
\label{golex:rules}

\subsection{Anatomy of a rule}

The general form of a \golex rule is:
\begin{alltt}
[\emph{<State>}] \emph{Matcher} => \emph{Body}
\end{alltt}
where the \q{\emph{<State>}} is optional (as is the body). If the body is omitted, then so is the arrow.

We discuss states in more detail in Section~\vref{golex:states}.

The \emph{Matcher} is a regular expression (see Section~\vref{golex:regexp}) that defines the strings that the rule 'fires' over.

The \emph{Body} decides how to interpret a successful match of the regular expression. There are three possibilities: to ignore the string, to produce a token expression, or to change state.

\begin{description}
\item[skip]
If the body of the rule consists of the word \q{skip}, or is omitted, then the effect is to ignore the matched string. No output is generated as a result of matching the matcher.

A classic use of this is, of course, to implement a comment facility in a lexer.

\item[expression]
If the \emph{Body} is text enclosed in parentheses, then it is interpreted as a \go expression. Some conditions apply to this expression:
\begin{itemize}
\item
The type of this expression must be \q{yyTokType}, or a sub-type of it.
\item
If the expression refers to the pseudo-variable \q{yyToken}, then that is replaced by a \q{string} that denotes the entire string that was matched by the rule.
\item
If the expression refers to the pseudo-variable \q{yyLine}, then that is replaced by an \q{integer} that represents the line number of the beginning of the matched string.
\item
If the expression refers to the pseudo-variable \q{yyLLine}, then that is replaced by an \q{integer} that represents the line number of the end of the matched string.
\item
If the expression refers to the pseudo-variable \q{yyPos}, then that is replaced by an \q{integer} that represents the number of characters in the complete string that are before the matched string.
\item
If the expression refers to the pseudo-variable \q{yyLPos}, then that is replaced by an \q{integer} that represents the number of characters in the complete string that are up to the end of the matched string.
\end{itemize}
The expression returned by the body of the rule is returned as the value of lexer itself, in particular, it is the returned value of the \q{nextToken} method applied to the lexer object.

\item[state]
If the \emph{body} is a state-name enclosed in \q{<>} characters then the matched string is ignored, but the state of the lexer is switched to the named state.
\end{description}

\section{Regular expressions}
\label{golex:regexp}
The matcher part of a rule takes the form of a regular expression. The language of regular expressions supported by \golex is very similar to the regular expression language of \q{lex} itself. This should aid in using \golex.

A regular expression consists of a sequence of elements of the form:
\begin{itemize}
\item
A string of characters, enclosed in \q{"} characters or \q{'} characters and following \go's standard escape conventions, matches exactly that string and no other.
\item
A period matches any character except the new-line character.
\item
A character set pattern of the form:
\begin{alltt}
[\emph{charSeq}\ldots\emph{charSeq}]
\end{alltt}
where \q{\emph{charSeq}} is either a regular \go character sequence or a range triplet of the form:
\begin{alltt}
\emph{charSeq}-\emph{charSeq}
\end{alltt}
matches any of the explicitly identified characters, or in the case of a range triplet any of the characters in the range.

For example, the pattern:
\begin{alltt}
[a-z_]
\end{alltt}
matches any lowercase ASCII letter and the underscore character.

There are some special considerations in the character set pattern: in order to include either of the \q{[]} characters themselves in the set, they should be escaped with a \bsl{} character. In order to include a \q{-} character it should be the first or the last character in the set, or escaped with a \bsl. In order to include the \q{\uphat} character it should not be the first character in the set.

\item
A negative character set pattern of the form:
\begin{alltt}
[\upht\emph{charSeq}\ldots\emph{charSeq}]
\end{alltt}
will match any character except those quoted.

\item
A pair of regular expressions separated by the \q{|} character indicates disjunction. I.e., a pattern of the form:
\begin{alltt}
\emph{P\sub1}|\emph{P\sub2}
\end{alltt}
will match any string that matches either of \q{\emph{P\sub1}} or \q{\emph{P\sub2}}.

\item
A pair of regular expressions with no separating characters is considered to match strings consisting of consequtive substrings that match the two component patterns.

\item
A regular expression followed by a \q{*} will match strings which match the left pattern any number of times (including zero). 

For example, the pattern:
\begin{alltt}
[a-z]*
\end{alltt}
matches any sequence of lowercase letters (including the empty set).

\item
A regular expression followed by a \q{+} will match strings which match the left pattern at least once.
For example, the pattern:
\begin{alltt}
[a-z]+
\end{alltt}
matches any sequence of lowercase letters (not including the empty string).

\item
A regular expression followed by a \q{?} will match strings which optionally match the left pattern.
For example, the pattern:
\begin{alltt}
[-+]?
\end{alltt}
optionally matches a character which is either \q{-} or \q{+}.

Note that this is optional only in the sense that the string may have a \q{-} or \q{+} character in it. If one of those characters were present the matches must match it!

\item
A regular expression enclosed in parentheses matches a string if the embedded regular expression matche the string.

\begin{aside}
The pattern language does not have any relative precedences for the regular expression operators. Hence, if there is any potential for ambiguity, then the regular expression pattern must fully parenthesized.
\end{aside}

\item
The regular expresion \q{eof} only matches the empty string at the end of the original input string.

\item
Any other character appearing in a regular expression pattern is considered an error, and will result in an error message generated by the \golex tool.
\end{itemize}


\section{Lexer states}
\label{golex:states}

The set of rules in a \golex file may be partitioned into named \emph{states}. Each state defines a set of rules that only apply to that state. In fact, if a rule does not have an explicit identifying state, its state is the default state -- also identified by the name \q{<initial>}.

Partitioning rules in this way is a powerful tool for implementing certain kinds of situation. For example, one might write a block comment rule:
\begin{alltt}
 "/*" => <comment>        	-- long comment

  <comment> "*/" => <initial>
  <comment> .	         	-- implies a skip
\end{alltt}
The leading \q{/*} characters cause a switch into the \q{<comment>} state. In this state, all characters are ignored (this follows from the single period matcher with an empty body) until the \q{*/} characters are matched. The rule for \q{*/} causes another switch, this time to the \q{<initial>} state, which is the default state.

If we did not have this concept of states, we would have to write the comment rule in a somewhat more elaborate form:
\begin{alltt}
"/*"([\upht{}*]|\bsl{}*[\upht{}/])*"*/"
\end{alltt}
\begin{aside}
The somewhat simpler rule:
\begin{alltt}
"/*".*"*/"
\end{alltt}
is not sufficient because the period \q{.} does not match a new-line.
\end{aside}

\section{Using a \golex lexer}
The \golex tool expects a rule file to have the extension \q{.glx}. Applying the \golex tool to this file results in a \go program of the same name and defining a package of the same name. This program must be compiled by the normal \go compiler before it can be used.

\begin{alltt}
\% golex \emph{lexer}.glx
\% goc \emph{lexer}.go
\end{alltt}

The \golex tool defines in \q{\emph{lexer}.go} a constructor whose name is \q{yy\emph{lexer}} that can be used to parse strings.

The type of \q{yy\emph{lexer}} is defined by the declaration:
\begin{alltt}
yy\emph{lexer}:[string,integer,integer]\sconarrow{}yyLexer.
\end{alltt}
where the first argument is the \q{string} to be analysed, the second is a notional start line and the third is a notional start position; and where \q{yyLexer} is defined using the type interface:
\begin{alltt}
yyLexer \impl \{ 
  nextToken:[]=>yyToken. 
  currentToken:[]=>yyToken. 
\}.
\end{alltt}
and \q{yyToken} itself is defined via the interface:
\begin{alltt}
yyToken \impl \{ 
  token:[]=>yyTokType. 
  isToken:[yyTokType]\{\}. 
  line:[]=>integer. 
  pos:[]=>integer. 
\}.
\end{alltt}

The \q{yyTokType} type is the type defined within the \q{.glx} file itself.

The methods in the \q{yyToken} type are:
\begin{description}
\item[token]
This returns the token expression that was returned by the tokenizer. It ultimately refers to the body of a rule in the \golex source file.

\item[isToken]
This is essentially a predicate form of the \q{token} function:
\begin{alltt}
\emph{Tk}.isToken(T) <=> \emph{Tl}.token()=T
\end{alltt}

\item[line]
This is the number of line numbers encountered in the original string before this token was recognized.

\item[pos]
This is the number of characters that are before the recognized sub-string in the original string.
\end{description}

The \q{yy\emph{lexer}} constructor constructs an object that can parse a string. It should be invoked with the string to parse, a number indicating the number of the first line and a number indicating the first character position:
\begin{alltt}
Lexer = yy\emph{lexer}(\emph{Input},0,0)
\end{alltt}
\begin{aside}
The case for non-zero values for the second and third arguments is when the lexer itself is only invoked on a fraction of the original input.
\end{aside}
To actually recognize a token, the \q{nextToken} function should be invoked from the tokenizer object itself:
\begin{alltt}
Tok = Lexer.nextToken()
\end{alltt}
The resulting object, which is of type \q{yyToken}, can be inspected for the returned token, where its line number and character position is.

